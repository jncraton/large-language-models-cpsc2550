{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f9e96-362a-4155-b740-8e356d96d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "from tokenizers import Tokenizer\n",
    "import ctranslate2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d916c3-f067-458f-8e71-d7a651523e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and initialize the tokenizer\n",
    "tok_config = hf_hub_download(\"jncraton/gte-small-ct2-int8\", \n",
    "                             \"tokenizer.json\")\n",
    "tokenizer = Tokenizer.from_file(tok_config)\n",
    "tokenizer.no_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1eebd-a9b5-4846-a7bc-4e8abdc2bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sample text\n",
    "tokens = tokenizer.encode(\"Hello, world\")\n",
    "tokens.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff30fa-a8aa-4abe-be80-aed79fb12d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and initialize the encoder\n",
    "path = snapshot_download(\"jncraton/gte-small-ct2-int8\", \n",
    "                         max_workers=1)\n",
    "encoder = ctranslate2.Encoder(path, \"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9185f1-c91e-4823-85c9-9adfb258e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a forward pass to compute last_hidden_state for our tokens\n",
    "outputs = encoder.forward_batch([tokens.ids])\n",
    "np.array(outputs.last_hidden_state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34abbcc-3336-4a5b-a08c-f943775617f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(docs):\n",
    "    \"\"\" Returns embeddings for list of documents \"\"\"\n",
    "    tokens = [tokenizer.encode(doc).ids for doc in docs]\n",
    "\n",
    "    def mean_pool(last_hidden_state):\n",
    "        embedding = np.mean(last_hidden_state, axis=0)\n",
    "        embedding = embedding / np.linalg.norm(embedding)\n",
    "        return embedding\n",
    "\n",
    "    outputs = encoder.forward_batch(tokens)\n",
    "    embeddings = [mean_pool(lhs) for lhs in np.array(outputs.last_hidden_state)]\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embed([\"Hello, world\"])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0ecd6-ceae-48ea-8354-c0e88917c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, embeddings):\n",
    "    \"\"\" Returns cosine similarity between query and embeddings \"\"\"\n",
    "    query_embedding = embed([query])[0]\n",
    "\n",
    "    scores = np.dot(embeddings, query_embedding)\n",
    "\n",
    "    return sorted(enumerate(scores), \n",
    "                  key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "embeddings = embed([\"Hello friend!\", \n",
    "                    \"Hello\", \n",
    "                    \"Get lost\", \n",
    "                    \"The capital of France is Paris\"])\n",
    "\n",
    "search(\"A nice greeting\", embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
